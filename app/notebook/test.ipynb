{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c45edd",
   "metadata": {},
   "source": [
    "### Using Python to read contents of PDF using OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763bd517",
   "metadata": {},
   "source": [
    "##### ⚠️ If you’re using multiple versions of Python (e.g., 3.12, 3.10), make sure pip matches the right version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pytesseract #A Python wrapper for Google’s Tesseract OCR engine\n",
    "!python -m pip install pdf2image #To convert PDF files into images\n",
    "!python -m pip install scipy\n",
    "!python -m pip install opencv-python #For image preprocessing tasks like deskewing and grayscale conversion\n",
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e0a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poppler path exists!\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\fkhaldi\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "poppler_path = r'C:\\Users\\fkhaldi\\Documents\\SUPMTI\\PFA\\colab\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin'\n",
    "\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "# poppler_path = r'C:\\Users\\ProBook\\Documents\\PFA\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin'\n",
    "\n",
    "if os.path.isdir(poppler_path):\n",
    "    print(\"Poppler path exists!\")\n",
    "else:\n",
    "    print(\"Poppler path does not exist!\")\n",
    "# PDF_file = \"../uploads/NASDAQ_ASLN_2019.pdf\"\n",
    "# PDF_file = \"../uploads/avis_concours.pdf\"\n",
    "PDF_file = \"../uploads/facture-avoir.pdf\"\n",
    "# PDF_file = \"../uploads/arabic_file.pdf\"\n",
    "\n",
    "# images = convert_from_path(PDF_file, poppler_path=poppler_path)\n",
    "\n",
    "# images[0].show()\n",
    "\n",
    "# IMAGE_FILE_LOCATION = \"../uploads/images/page_1.jpg\"\n",
    "# img = Image.open(IMAGE_FILE_LOCATION)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Part #1 : Converting PDF to images\n",
    "'''\n",
    "\n",
    "# Store all the pages of the PDF in a variable\n",
    "pages = convert_from_path(PDF_file, 200, poppler_path=poppler_path)\n",
    "# pages = convert_from_path(PDF_file, poppler_path=poppler_path)\n",
    "\n",
    "# Counter to store images of each page of PDF to image\n",
    "image_counter = 1\n",
    "\n",
    "# Iterate through all the pages stored above\n",
    "for page in pages:\n",
    "    # Declaring filename for each page of PDF as JPG\n",
    "    # For each page, filename will be:\n",
    "    # PDF page 1 -> page_1.jpg\n",
    "    # PDF page 2 -> page_2.jpg\n",
    "    # PDF page n -> page_n.jpg\n",
    "    filename = \"../uploads/images/page_\"+str(image_counter)+\".jpg\"\n",
    "\n",
    "    # Save image of the page in system\n",
    "    page.save(filename, 'JPEG')\n",
    "\n",
    "    # Increase counter to update filename\n",
    "    image_counter = image_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3164488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Part #2 - Recognising text from the images using OCR\n",
    "'''\n",
    "\n",
    "# Variable to get count of total number of pages\n",
    "filelimit = image_counter-1\n",
    "\n",
    "# Create a text file to write the output\n",
    "outfile = \"../outputs/output_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9372f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in append mode so that contents of all images are added to the same file\n",
    "f = open(outfile, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "# Iterate from 1 to the total number of pages\n",
    "for i in range(1, filelimit + 1):\n",
    "\n",
    "    # Set filename to recognize text from\n",
    "    # page_1.jpg\n",
    "    # page_2.jpg\n",
    "    # page_n.jpg\n",
    "    filename = \"../uploads/images/page_\"+str(i)+\".jpg\"\n",
    "\n",
    "    # # Load image and preprocess\n",
    "    # img = cv2.imread(filename)\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # gray = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)[1]  # binarization\n",
    "    # gray = cv2.medianBlur(gray, 3)\n",
    "\n",
    "    # Optional: Save to verify output\n",
    "    # cv2.imwrite(\"../uploads/images/cleaned_\"+str(i)+\".jpg\", gray)\n",
    "\n",
    "    # Load and preprocess\n",
    "    image = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)  # Noise reduction\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Save cleaned image (optional)\n",
    "    cv2.imwrite(\"../uploads/images/cleaned_\"+str(i)+\".jpg\", gray)\n",
    "\n",
    "    # Recognise the text as string in image using pytesserct\n",
    "    # text = str(((pytesseract.image_to_string(Image.open(filename), lang=\"ara\"))))  # or 'fra', 'ara', etc\n",
    "    # custom_config = r'--oem 3 --psm 3 -l ara'\n",
    "    custom_config = r'--oem 3 --psm 3 -l fra'\n",
    "    # text = pytesseract.image_to_string(thresh, config=custom_config)\n",
    "    text = str(((pytesseract.image_to_string(thresh, config=custom_config , lang=\"fra\"))))  # or 'fra', 'ara', etc\n",
    "\n",
    "    # The recognized text is stored in variable text\n",
    "    # Any string processing may be applied on text\n",
    "    # Basic formatting has been performed\n",
    "    # In many PDFs, if a word can't be written fully at line ending, a 'hyphen' is added\n",
    "    # The rest of the word is written in the next line\n",
    "    # Replace every '-\\n' to '' to remove such hyphens\n",
    "    # text = text.replace('-\\n', '')\n",
    "\n",
    "    # Write the processed text to the file\n",
    "    f.write(text)\n",
    "\n",
    "# Close the file after writing all the text\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c324a8c",
   "metadata": {},
   "source": [
    "### Using Tesseract OCR to localise and detect text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8de7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input image\n",
    "IMAGE_FILE_LOCATION = \"../uploads/images/page_1.jpg\"\n",
    "input_img = cv2.imread(IMAGE_FILE_LOCATION)\n",
    "\n",
    "scale_percent = 50 # Percent of original size\n",
    "width = int(input_img.shape[1] * scale_percent / 100)\n",
    "height = int(input_img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# Resize input image\n",
    "resized = cv2.resize(input_img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2d2a0",
   "metadata": {},
   "source": [
    "#### Step 1: Select the region of interest (“ROI”) from the resized input image using the mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97c8e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Coordinates received. Cropping ROI...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list for storing the coordinates \n",
    "coordinates = [] \n",
    "  \n",
    "# Define callback function\n",
    "def shape_selection(event, x, y, flags, param): \n",
    "    global coordinates # Make coordinates global\n",
    "  \n",
    "    # Store the (x1,y1) coordinates when left mouse button is pressed  \n",
    "    if event == cv2.EVENT_LBUTTONDOWN: \n",
    "        coordinates = [(x, y)] \n",
    "  \n",
    "    # Store the (x2,y2) coordinates when the left mouse button is released and make a rectangle on the selected region\n",
    "    elif event == cv2.EVENT_LBUTTONUP: \n",
    "        coordinates.append((x, y)) \n",
    "  \n",
    "        # Draw a rectangle around the region of interest\n",
    "        cv2.rectangle(image, coordinates[0], coordinates[1], (0,0,255), 2) \n",
    "        cv2.imshow(\"image\", image) \n",
    "        \n",
    "# Load and make a copy of the image, and setup the mouse callback function \n",
    "image = resized\n",
    "image_copy = image.copy()\n",
    "cv2.namedWindow(\"image\") \n",
    "cv2.setMouseCallback(\"image\", shape_selection) \n",
    "   \n",
    "# Keep looping until the 'q' key is pressed \n",
    "while True: \n",
    "    # Display the image and wait for a keypress \n",
    "    cv2.imshow(\"image\", image) \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "  \n",
    "    if key==13: # If 'enter' is pressed, apply OCR\n",
    "        break\n",
    "    \n",
    "    if key == ord(\"c\"): # Clear the selection when 'c' is pressed \n",
    "        image = image_copy.copy() \n",
    "\n",
    "# if len(coordinates) == 2: \n",
    "#     image_roi = image_copy[coordinates[0][1]:coordinates[1][1],\n",
    "#                            coordinates[0][0]:coordinates[1][0]] \n",
    "#     cv2.imshow(\"Selected Region of Interest - Press any key to proceed\", image_roi) \n",
    "#     cv2.waitKey(0) \n",
    "\n",
    "if len(coordinates) == 2: \n",
    "    print(\"[INFO] Coordinates received. Cropping ROI...\")  # Debug print\n",
    "    image_roi = image_copy[coordinates[0][1]:coordinates[1][1],\n",
    "                           coordinates[0][0]:coordinates[1][0]] \n",
    "    cv2.imshow(\"Selected Region of Interest - Press any key to proceed\", image_roi) \n",
    "    cv2.waitKey(0) \n",
    "else:\n",
    "    print(\"[WARNING] ROI not selected properly. Length of coordinates:\", len(coordinates))\n",
    "\n",
    "\n",
    "# Close all open windows \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee64dba",
   "metadata": {},
   "source": [
    "#### Step 2: Perform Tesseract OCR on the region of interest selected and print the output text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deffec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 221, 3)\n",
      "The text in the selected region is as follows:\n",
      "\n",
      "Nom du client\n",
      "Adresse du client\n",
      "Code postal et ville du client\n",
      "\n",
      "I TVA duclient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(image_roi.shape)\n",
    "\n",
    "text = pytesseract.image_to_string(image_roi)\n",
    "print(\"The text in the selected region is as follows:\\n\")\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
